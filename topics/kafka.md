## Введение

Apache Kafka - это распределенная платформа потоковой передачи данных (event streaming platform), которая позволяет надёжно передавать, хранить и обрабатывать большие объёмы событий в реальном времени.

Для системного аналитика Kafka важна не как "ещё один брокер", а как архитектурный инструмент, который влияет на:
- границы сервисов;
- контракт событий;
- согласованность данных;
- нефункциональные требования (производительность, доступность, восстановление, аудит);
- подход к интеграциям и эволюции системы.

Эта статья построена в 3 слоя:
1. Обзорный: что такое Kafka и где она уместна.
2. Прикладной: как проектировать решения с Kafka на уровне SA.
3. Технический: как Kafka работает внутри и что важно обсуждать на senior-собеседованиях.

Отдельно в конце: блок "что говорить на интервью" с готовыми формулировками, типичными вопросами и анти-паттернами ответов.

## Часть 1. Обзорный уровень

### Что такое Kafka в одной формулировке

Kafka - это распределенный commit log, поверх которого построена модель pub/sub и потоковой обработки.

Ключевая мысль: Kafka не просто "пересылает" сообщения, а хранит последовательность событий в течение заданного времени. Это позволяет:
- перечитывать историю;
- строить новые потребители без изменения продюсеров;
- делать replay после багов или изменения логики;
- использовать события как источник правды для аналитики и интеграций.

### Когда Kafka обычно выбирают

Kafka хорошо подходит, если есть:
- высокий поток событий (десятки/сотни тысяч+ сообщений в секунду);
- много независимых потребителей одних и тех же данных;
- потребность в near real-time обработке;
- необходимость хранить поток событий и переобрабатывать историю;
- события как фундамент EDA/CQRS/streaming analytics.

### Когда Kafka часто избыточна

Kafka может быть не лучшим выбором, если:
- у вас 1-2 интеграции и низкая нагрузка;
- нужен простой task queue сценарий "взял-задачу-сделал";
- команде критична минимальная операционная сложность;
- нет потребности в replay и event-driven архитектуре.

В таких случаях RabbitMQ, SQS или даже синхронное API-взаимодействие могут быть проще и дешевле.

### Базовые сущности, которые обязан знать SA

- `Broker`: сервер Kafka, который хранит партиции топиков.
- `Topic`: логическая категория событий.
- `Partition`: упорядоченный append-only лог внутри топика.
- `Offset`: позиция сообщения в партиции.
- `Producer`: публикует события.
- `Consumer`: читает события.
- `Consumer Group`: механизм масштабирования чтения (1 партиция -> максимум 1 активный consumer внутри одной группы).
- `Replication factor`: количество копий партиции.
- `Retention`: как долго Kafka хранит события.

### Гарантии доставки (важно формулировать точно)

- `At-most-once`: событие может потеряться, но не будет дубликатов.
- `At-least-once`: потерь почти нет, но возможны дубликаты.
- `Exactly-once` (в Kafka - ограниченный контекст): достигается комбинацией идемпотентного продюсера + транзакций + корректной логики обработки.

На собеседовании правильно говорить: "Exactly-once - это не магия кластера, а end-to-end дисциплина (брокер + клиент + бизнес-обработка)".

## Часть 2. Прикладной уровень для системного аналитика

### 1. Моделирование событий

Главная ошибка - публиковать "технические" события вместо бизнес-событий.

Хороший подход:
- событие фиксирует бизнес-факт в прошедшем времени (`OrderCreated`, `PaymentCaptured`, `OrderCancelled`);
- имя отражает домен, а не таблицу БД;
- событие иммутабельно (не редактируется "задним числом");
- полезная нагрузка достаточна для потребителей, но без лишнего шума.

Практическая структура события:

```json
{
  "event_id": "2f94f9b6-62f4-4f20-9abc-2fa8795f8a8c",
  "event_type": "OrderCreated",
  "event_version": 3,
  "occurred_at": "2026-02-07T10:15:30Z",
  "producer": "order-service",
  "trace_id": "f4ef4b5f2f1e4d8a",
  "key": "order-784512",
  "payload": {
    "order_id": "784512",
    "customer_id": "C-1942",
    "amount": 14990,
    "currency": "RUB"
  }
}
```

### 2. Ключ партиционирования и порядок

В Kafka порядок гарантирован только внутри одной партиции.

Если нужен порядок по заказу/клиенту/счёту, ключ должен быть стабильным:
- `key = order_id` для порядка событий по заказу;
- `key = customer_id` для порядка по клиенту.

Компромисс: чем "уже" ключ, тем выше риск hot partition.

Что SA должен уточнять в требованиях:
- по какой сущности критичен порядок;
- где допустима частичная перестановка;
- нужна ли глобальная последовательность (обычно нет и дорого).

### 3. Контракты и версионирование схем

Без схем и совместимости Kafka быстро превращается в "болото JSON".

Рекомендуемый подход:
- формализовать схему (Avro/Protobuf/JSON Schema);
- хранить версии в Schema Registry;
- определить политику совместимости (`backward`/`forward`/`full`);
- избегать breaking changes без миграционного окна.

Практическое правило:
- новые поля добавлять как optional/default;
- не удалять/не переименовывать поля резко;
- для больших изменений выпускать новую версию события (`OrderCreatedV2` или `event_version`).

### 4. Идемпотентность и дубликаты

SA должен изначально считать, что дубликаты возможны.

Анти-дубли стратегии:
- уникальный `event_id` + dedup-таблица на стороне consumer;
- upsert вместо "слепой вставки";
- бизнес-ключи уникальности (например, внешняя операция платежа);
- outbox-паттерн у продюсера.

Формулировка для интервью:
"Kafka снижает риск потерь, но бизнес-идемпотентность - ответственность прикладного слоя".

### 5. Retry, DLQ и обработка ошибок

Нельзя ограничиться "если ошибка - ретрай бесконечно".

Минимальный шаблон:
- transient ошибки -> ограниченный retry с backoff;
- poison message / schema mismatch -> в DLQ;
- алерты и операционный процесс разбора DLQ;
- traceability: по `event_id` можно восстановить путь события.

### 6. Семантика доставки и commit offset

Критический момент: когда коммитить offset.

Безопасный базовый подход:
- прочитали событие;
- успешно применили бизнес-изменение;
- только после этого commit offset.

Иначе возможны:
- ранний commit -> потеря обработки;
- поздний/хаотичный commit -> повторы.

### 7. Kafka и транзакционные границы

Частая проблема: "записали в БД, но событие не отправили" или наоборот.

Практики:
- Transactional Outbox (самая популярная для микросервисов);
- CDC (например, Debezium) при интеграции с legacy;
- Saga для распределённых бизнес-процессов.

### 8. Нефункциональные требования, которые SA должен фиксировать

- целевая задержка (p95/p99 end-to-end);
- требуемый throughput;
- допустимая потеря данных (обычно 0 для критичных доменов);
- RPO/RTO;
- срок хранения событий;
- требования к replay (сколько исторических данных нужно переиграть);
- требования безопасности (шифрование, аутентификация, ACL).

### 9. Наблюдаемость

Базовый набор метрик:
- producer error rate, retry rate;
- consumer lag;
- DLQ rate;
- rebalance frequency/duration;
- throughput по топикам и партициям;
- end-to-end latency от `occurred_at` до факта обработки.

Если нет мониторинга lag и DLQ, система с Kafka обычно "ломается тихо".

## Часть 3. Технический уровень

### 1. Внутренняя модель хранения

Kafka хранит данные в сегментах лога на диске. Запись идёт последовательно (append), за счёт чего достигается высокая пропускная способность.

Удаление/очистка:
- `retention.ms` и/или `retention.bytes`;
- log compaction (хранение последнего значения по ключу).

Compaction нужен для сценариев "текущее состояние по ключу" (справочники, профиль клиента), retention - для событийной истории.

### 2. Репликация, ISR и отказоустойчивость

Для каждой партиции есть:
- `leader` - принимает запись/чтение;
- `followers` - реплики.

ISR (in-sync replicas) - реплики, которые успевают за лидером.

Надёжные настройки продюсера:
- `acks=all`;
- `enable.idempotence=true`;
- `min.insync.replicas >= 2` (обычно вместе с replication factor >= 3).

Смысл: запись подтверждается только когда событие зафиксировано на минимально безопасном числе реплик.

### 3. Producer pipeline и порядок отправки

Важные параметры:
- `linger.ms` и `batch.size` влияют на batching/latency;
- `max.in.flight.requests.per.connection` влияет на риск перестановки при ретраях;
- `compression.type` (`snappy`, `lz4`, `zstd`) влияет на компромисс CPU/сеть/диск.

Практика:
- для строгого порядка + идемпотентности избегать чрезмерно высоких `max.in.flight`;
- подбирать `linger.ms` под SLA задержки.

### 4. Consumer group protocol и rebalance

При изменении состава группы запускается rebalance: партиции перераспределяются.

Риски:
- пауза в обработке;
- дубли при некорректном commit;
- рост lag.

Что помогает:
- cooperative-sticky assignor;
- static membership;
- предсказуемое время обработки (не блокировать poll-loop тяжёлыми операциями).

### 5. Exactly-once semantics (EOS) в реальности

EOS в Kafka возможен для сценариев read-process-write в Kafka (особенно с Kafka Streams), но при выходе во внешние системы нужна прикладная защита.

Ключевой тезис для интервью:
"Exactly-once в распределённой системе - это комбинация брокерных механизмов и идемпотентной бизнес-логики на границах".

### 6. Kafka Streams и stateful processing

Kafka Streams даёт:
- state stores;
- windowed operations;
- joins потоков;
- event-time processing.

SA должен понимать минимум:
- разницу event time vs processing time;
- late events и watermark/punctuation стратегии;
- как window влияет на бизнес-результат (например, антифрод/лимиты).

### 7. Безопасность

Обычно в enterprise-кластерах используют:
- TLS (шифрование трафика);
- SASL/SCRAM или mTLS/Kerberos для аутентификации;
- ACL/RBAC для авторизации.

На уровне требований нужно фиксировать:
- кто может publish/consume по каждому топику;
- как изолируются среды (dev/test/prod);
- аудит операций и ротация секретов.

### 8. Multi-cluster и DR

Для геораспределения и disaster recovery применяют репликацию между кластерами (например, Cluster Linking/MirrorMaker-подходы).

Что SA обязан уточнять:
- актив-актив или актив-пассив;
- допустимый лаг репликации;
- правила разрешения конфликтов при failover;
- процедура возврата после аварии.

## Что говорить на собеседовании системному аналитику

### Каркас сильного ответа "Что такое Kafka и зачем она"

"Kafka - это распределённый commit log для событийных интеграций и stream processing. Она подходит, когда нужны высокая пропускная способность, декуплинг продюсеров и потребителей, хранение истории и replay. В проектировании я отдельно фиксирую ключ партиционирования, правила версионирования схем, идемпотентность потребителей, стратегию retry/DLQ и метрики lag/latency, чтобы система была не только быстрой, но и операционно управляемой".

### Частые вопросы и опорные тезисы

1. В чём разница Kafka и RabbitMQ?
- Kafka: event log, replay, высокая пропускная способность, масштабирование через партиции.
- RabbitMQ: гибкая маршрутизация и классическая очередь задач.
- Выбор зависит от паттерна нагрузки и требований к истории событий.

2. Как обеспечить порядок событий?
- Порядок только внутри партиции.
- Выбирать ключ по бизнес-сущности, где критична последовательность.

3. Как избежать потерь и дубликатов?
- `acks=all`, replication factor 3, min ISR 2.
- Идемпотентный producer + идемпотентный consumer.
- Commit offset только после успешной обработки.

4. Что делать с невалидными сообщениями?
- Валидировать схему.
- Poison messages отправлять в DLQ.
- Нужен операционный регламент разбора DLQ.

5. Как версионировать события?
- Эволюционно и совместимо.
- Schema Registry + политика совместимости.
- Breaking change через новую версию контракта.

6. Какие метрики ключевые?
- consumer lag, end-to-end latency, error/retry rate, rebalance, DLQ volume.

### Типичные ошибки кандидатов

- Говорят, что Kafka гарантирует глобальный порядок (неверно).
- Обещают "exactly once везде" без оговорки про внешние системы.
- Не различают event и command.
- Не упоминают схему/версионирование.
- Не понимают, когда коммитится offset и чем это чревато.
- Не учитывают операционку: мониторинг, DLQ, runbook.

### Мини-кейсы для интервью (как отвечать)

1. "После внедрения Kafka начали дублироваться операции"
- Проверить commit offset, retry-политику, идемпотентность consumer.
- Добавить dedup по `event_id` и бизнес-ключам.

2. "У нас высокий lag в пиковые часы"
- Проверить баланс партиций, hot keys, скорость обработки.
- Масштабировать consumers и/или увеличить партиции с учётом ключа.
- Убедиться, что тяжёлые I/O операции вынесены из poll-loop.

3. "Нужно поменять структуру события без остановки систем"
- Ввести новую версию схемы с backward compatibility.
- Поддержать переходный период для потребителей.
- Контролировать долю старых/новых форматов через метрики.

## Практический чек-лист SA перед запуском Kafka-интеграции

- Определены бизнес-события и их владельцы.
- Зафиксирован ключ партиционирования и правило порядка.
- Утверждён формат контракта и политика версионирования.
- Определены гарантии доставки и commit стратегия.
- Спроектированы retry, DLQ, dedup.
- Согласованы retention/compaction параметры под бизнес.
- Описаны SLA/SLO и метрики мониторинга.
- Подготовлены runbook и ответственность команд.

## Заключение

Kafka даёт системному аналитику мощный инструмент для построения масштабируемой событийной архитектуры, но успех зависит не от факта "подключили брокер", а от качества проектирования контрактов, обработки ошибок, идемпотентности и операционных процессов.

На собеседовании сильный ответ про Kafka всегда сочетает:
- архитектурный уровень (зачем и где применять),
- прикладной уровень (как проектировать события и потоки),
- технический уровень (как это реально работает под нагрузкой и при сбоях).

Именно такая связка отличает уверенного SA от кандидата, который знает только термины.
