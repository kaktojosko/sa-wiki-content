## Введение

LLM (Large Language Models) могут существенно ускорить работу системного аналитика: от исследования домена до подготовки требований и проверки консистентности документации. Ключевой принцип: LLM - это помощник, а не источник безусловной истины.

## Основные концепции

### Где LLM полезен

* **Разбор входящих материалов:** суммаризация длинных документов и протоколов встреч.
* **Подготовка черновиков:** user story, use case, acceptance criteria, чеклисты.
* **Нормализация терминов:** выявление дубликатов и противоречий в глоссарии.
* **Поддержка API-работы:** генерация примеров запросов/ответов и edge-cases.
* **Подготовка вопросов к интервью:** структурирование discovery-сессий.

### Ограничения

* возможны галлюцинации;
* модель может "придумывать" несуществующие факты;
* ответ зависит от качества контекста.

Поэтому у аналитика всегда остаётся зона ответственности за проверку, источники и финальное решение.

### Принцип "контекст + критерии качества"

Хороший промпт обычно включает:

* роль модели;
* контекст проекта;
* формат ответа;
* критерии качества;
* ограничения.

Пример:

```text
Ты системный аналитик платежной платформы.
На основе требований ниже сформируй 10 acceptance criteria в формате Given-When-Then.
Не добавляй новых бизнес-правил.
Если данных недостаточно - перечисли вопросы.
```

## Практические сценарии

### Пример 1: подготовка user story и AC

Вход: описание процесса возврата.  
Выход от LLM:

* user story;
* acceptance criteria;
* список открытых вопросов.

Это экономит время на первом черновике, но аналитик обязан проверить полноту и соответствие бизнес-правилам.

### Пример 2: анализ консистентности требований

LLM можно попросить:

* найти конфликтующие правила;
* отметить термины без определения;
* выделить места с неоднозначными формулировками ("быстро", "в разумный срок").

### Пример 3: подготовка тестовых сценариев

На основе API-спецификации модель может предложить:

* позитивные сценарии;
* негативные сценарии;
* граничные значения;
* проверки на backward compatibility.

## Практика безопасного использования

* Не передавайте в внешние модели чувствительные данные без согласования.
* Анонимизируйте персональные и финансовые данные.
* Фиксируйте, где LLM использовался и что именно сгенерировано.
* Используйте корпоративные LLM-решения при наличии требований по безопасности.

## Типичные ошибки и как их избежать

* **Слепое копирование ответа LLM:** ошибки переходят в требования.  
  **Решение:** обязательная экспертная верификация.
* **Слабый контекст в промпте:** поверхностный результат.  
  **Решение:** указывать домен, ограничения, формат и критерии.
* **Нарушение политики ИБ:** утечки данных.  
  **Решение:** маскирование данных и использование разрешённых инструментов.

## Связь с другими темами

Тема связана с `DocOps`, `Jira и Confluence`, `Git`, `Swagger/OpenAPI` и `Инструментами аналитика` как часть современного рабочего процесса.

## Заключение

LLM даёт системному аналитику ускорение в рутинных задачах, но качество результата определяется дисциплиной: корректным контекстом, проверкой фактов и ответственным отношением к данным.
