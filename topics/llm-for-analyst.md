## Введение

LLM (Large Language Models) могут существенно ускорить работу системного аналитика: от исследования домена (предметной области) до подготовки требований и проверки консистентности документации. 

Ключевой принцип: LLM - это помощник, а не источник безусловной истины.

> Воспринимайте LLM как студента-первокурсника, который очень старается, но у него не всегда получается

LLM это машина по угадыванию следующего слова. И угадывает она очень хорошо. Настолько хорошо, что у людей возникает иллюзия наличия разума у LLM.

LLM это вероятностный движок, который стремится угадать следующее слово и угодить пользователю.

## Кратко

> TR/PC+ABCPtEFFS/R(CoT)(ToT+E)(BotB/I)[MS-CT][MS-SI]

> если запомнить эту _простую_ аббревиатуру, то ваши запросы вырастут в качестве

T - Task - Что должна сделать модель

R/P - Role / Persona - В какой роли ИИ находится, чтобы сделать задачу

C+ABC - Context+Always Be Contexting - Что ИИ должен знать+всегда предоставляй контекст

PtF - Permission to Fail - ИИ нужно успокаивать и сообщить модели, что у неё есть право на ошибку или на ответ "Я не знаю"

F - Format - Требования к выходной информации

FS/R - Few Shot / References (хорошие примеры, которые повторить / на которые ориентироваться)

(CoT) - Chain of Thought - **Только для недумающих моделей**. Пусть ИИ пишет что думает. Это нужно указать в промпте, чтобы в ответе был написан поток мысли и лишь после этого потока был сформирован финальный ответ

(ToT+E) - Trees of Thought + Evaluate - пусть ИИ проводит брейншторм и выдаёт по 3 пути решения / 3 варианта. ПОТОМ И ТОЛЬКО ПОТОМ пусть ИИ оценит каждую ветвь мыслей. ПОТОМ пусть напишет финальный ответ на основании лучшего варианта

(BotB/I) - Battle of the Bots / Iterate - пусть ИИ генерирует конкурирующие/противостоящие друг другу варианты - пусть генерит их в 3 раунда и пусть каждый отдельный вариант генерируются отдельной ИИ личностью (смотри R/P - Role/Persona). Две роли генерят ответы со своих позиций, а пусть третья роль будет ОЧЕНЬ ЗЛЫМ клиентом/критиком и они ВТРОЁМ **должны** работать сообща и прийти к одному объединенному решению, которое синтезировано из результатов прошлых раундов:

* РАУНД 1 - черновички роли 1 и роли 2
* РАУНД 2 - роль 3 ЖОСКО критикует черновички
* РАУНД 3 - синтез ответа

[MS-CT] - Meta Skill-Clear Thinking - Это уже ваш навык - чет точнее и чище описан желаемый результат, тем лучше будет результат

[MS-SI] - Meta Skill-Skill Issue - если у вас есть проблема с нейронкой, то это стоит воспринимать это как личный **skill issue**


## Основные концепции

### Где LLM полезен

* **Разбор входящих материалов:** суммаризация длинных документов и протоколов встреч.
* **Подготовка черновиков:** user story, use case, acceptance criteria, чеклисты.
* **Нормализация терминов:** выявление дубликатов и противоречий в глоссарии.
* **Поддержка API-работы:** генерация примеров запросов/ответов и edge-cases.
* **Подготовка вопросов к интервью:** структурирование discovery-сессий.

### Ограничения

* возможны галлюцинации - LLM любят придумывать информацию, лишь бы ответить на вопрос
* ответ зависит от качества контекста - контекст это самое важное что может быть
* LLM не ответственны за свой ответ - они просто отвечают

Поэтому у аналитика всегда остаётся зона ответственности за проверку, источники и финальное решение.

### Принцип "контекст + критерии качества"

Хороший промпт обычно включает:

* роль модели;
* контекст проекта;
* формат ответа;
* критерии качества;
* ограничения.

Другой фреймвок как делать запросы к LLM это TCREI от Гугла:
* Task - задача для модели и РОЛЬ модели
* Context - информация, которую должна знать LLM для более успешного выполнения задачи
* References - примеры как делать задачу / каким вы хотели бы видеть результат
* Evaluation - требования, которые модель должна соблюдать
* Iteration - пусть LLM создаст не 1 вариант ответа, а 3-5. Среди этого набора выберите лучший

Пример:

```text
Ты системный аналитик платежной платформы.
На основе требований ниже сформируй 10 acceptance criteria в формате Given-When-Then.
Не добавляй новых бизнес-правил.
Если данных недостаточно - перечисли вопросы.
```

## Практические сценарии

### Пример 1: подготовка user story и AC

Вход: описание процесса возврата.  
Выход от LLM:

* user story;
* acceptance criteria;
* список открытых вопросов.

Это экономит время на первом черновике, но аналитик обязан проверить полноту и соответствие бизнес-правилам.

### Пример 2: анализ консистентности требований

LLM можно попросить:

* найти конфликтующие правила;
* отметить термины без определения;
* выделить места с неоднозначными формулировками ("быстро", "в разумный срок").

### Пример 3: подготовка тестовых сценариев

На основе API-спецификации модель может предложить:

* позитивные сценарии;
* негативные сценарии;
* граничные значения;
* проверки на backward compatibility.

## Практика безопасного использования

* Не передавайте в внешние модели чувствительные данные без согласования.
* Анонимизируйте персональные и финансовые данные.
* Фиксируйте, где LLM использовался и что именно сгенерировано.
* Используйте корпоративные LLM-решения при наличии требований по безопасности.

## Типичные ошибки и как их избежать

* **Слепое копирование ответа LLM:** ошибки переходят в требования, а вы теряете авторитет аналитика.
  **Решение:** обязательная экспертная верификация, подключать в работе голову.
* **Слабый контекст в промпте:** поверхностный и бездумный результат.
  **Решение:** указывать домен, ограничения, формат и критерии.
* **Нарушение политики ИБ:** утечки данных.
  **Решение:** маскирование данных и использование разрешённых инструментов. Используйте внутрекорпоративные LLM, не загоняйте конфиденциальную информацию в LLM

## Связь с другими темами

Тема связана с `DocOps`, `Jira и Confluence`, `Git`, `Swagger/OpenAPI` и `Инструментами аналитика` как часть современного рабочего процесса.

## Заключение

LLM даёт аналитику ускорение в рутинных задачах, но ответственность за качество результата лежит на аналитике. Если вы один раз опозоритесь с тем, что написали в документации так называемый AI SLOP, то **все** ваши дальнейшие постановки задач будут под сомнением. Авторитет аналитика вещь важная. Вас берут на работу не из-за способности писать запросы к LLM, а из-за хорошо работающей головы на плечах
