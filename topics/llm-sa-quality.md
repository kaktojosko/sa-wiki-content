# Введение

LLM уже стали рабочим инструментом аналитика, но главная фича в том, что LLM позволяет повысить качество артефактов. 

Хороший аналитик использует LLM не как "вот задача, сделай за меня", а как генератор идей и помощника в проверке полноты, непротиворечивости и тестируемости.

> LLM не заменяет мышление аналитика, а усиливает контроль качества

## Где качество растёт

- Требования становятся более проверяемыми и однозначными.
- Раньше находятся противоречия между документами и диаграммами.
- Снижается количество пропущенных edge cases.
- Улучшается трассируемость: от бизнес-цели до тест-кейса.
- Команда получает более чистый контекст для оценки и реализации.

## Пример 1. Улучшение сырого требования до тестируемого

Сырой вариант:

> "Система должна быстро отправлять уведомления пользователям."

Проблемы качества:

- Нет метрики "быстро".
- Не указан канал (email, push, sms).
- Не определены условия отказа и ретраев.
- Невозможно однозначно принять работу.

Как использовать LLM:

- Попросить найти неоднозначности.
- Попросить переписать требование в формате "событие -> действие -> SLA -> исключения".
- Попросить сформировать acceptance criteria.

Результат:

> "При смене статуса заказа на `SHIPPED` система отправляет push-уведомление в течение 30 секунд для 95% событий.  
> Если push недоступен, выполняются 3 ретрая с интервалом 10 секунд.  
> После 3 неудачных попыток создается запись в журнале ошибок уровня `WARN`."

Что улучшилось:

- Появились измеримые критерии.
- Добавлены негативные сценарии.
- Требование стало проверяемым.

## Пример 2. Проверка User Story по чек-листу качества

Черновик:

> "Как менеджер, я хочу видеть отчеты по продажам, чтобы принимать решения."

Запрос к LLM:

- Проверь по INVEST.
- Найди отсутствующие критерии приемки.
- Предложи минимальный набор сценариев для QA.

Типичный результат:

- Story слишком широкая: "отчеты по продажам" надо декомпозировать (дневной, недельный, по сегментам).
- Не определен период, фильтры и уровень детализации.
- Нет ограничений по времени загрузки.

Улучшенный вариант:

> "Как региональный менеджер, я хочу видеть недельный отчет по продажам с фильтрами `регион`, `канал`, `категория`, чтобы сравнивать динамику по неделям."  
> AC1: отчет строится не дольше 5 секунд для периода до 12 недель.  
> AC2: значения совпадают с витриной `sales_weekly_mart` с точностью до 0.1%.  
> AC3: при отсутствии данных отображается состояние `Нет данных` без ошибки 500.

Фокус на качестве: уменьшается риск "приняли не то, что хотели".

## Пример 3. Поиск противоречий между артефактами

Практика: аналитик передает LLM три фрагмента:

- Описание бизнес-процесса.
- Диаграмму последовательности.
- API-контракт (OpenAPI/JSON Schema).

Запрос:

> "Найди логические противоречия и отсутствующие переходы. Отдельно укажи риски для продакшена."

Что LLM обычно находит:

- В процессе есть шаг "ручное подтверждение", а в API нет статуса `PENDING_APPROVAL`.
- В диаграмме есть callback, но в контракте не описан webhook payload.
- В требованиях есть idempotency, но в API нет `Idempotency-Key`.

Почему это про качество:

- Такие дефекты дорогие, если выявляются только на интеграционном тестировании.
- Ранняя сверка артефактов снижает архитектурный долг.

## Пример 4. Генерация edge cases и негативных сценариев

Проблема: в документации обычно хорошо описан "happy path", но слабые места почти всегда в исключениях.

Запрос к LLM:

> "Для этого use case сгенерируй 20 edge cases: данные, таймауты, гонки, дубликаты, частичные отказы."

Полезные категории, которые стоит требовать явно:

- Некорректные и частично заполненные входные данные.
- Повторная отправка одного и того же запроса.
- Истечение токена в середине бизнес-операции.
- Расхождение данных между кэшем и источником истины.
- Повторная доставка события из брокера.

Фокус на качестве:

- Растет устойчивость системы к реальным условиям.
- Снижается количество дефектов "не воспроизводится локально".

## Пример 5. Контроль терминологии и глоссария

Типичная проблема: в разных документах одно и то же называется по-разному (`клиент`, `покупатель`, `контрагент`).

Запрос к LLM:

> "Проверь терминологическую консистентность документов. Составь таблицу: термин -> определение -> где используется -> конфликтующие синонимы."

Что это дает:

- Снижается риск ошибок интеграции и неверной разработки.
- Ускоряется онбординг новых участников команды.
- Повышается прозрачность коммуникации бизнеса и IT.

## Пример 6. Трассируемость

Сильный сценарий применения LLM:

- На вход: бизнес-цель, набор функциональных требований, черновые тест-кейсы.
- На выход: матрица трассируемости с пробелами.

Запрос:

> "Сопоставь бизнес-цели с требованиями и тест-кейсами. Покажи, какие цели не покрыты, и где есть требования без тестов."

Эффект на качество:

- Видно, где тратится разработка без бизнес-ценности.
- Видно, какие критичные требования никто не проверяет.
- Проще проходить аудит и регуляторные проверки.

## Практический шаблон работы аналитика с LLM

1. Сначала написать черновик самостоятельно.
2. Передать LLM конкретную роль: `QA reviewer`, `solution architect reviewer`, `product owner reviewer`.
3. Дать явный чек-лист качества: однозначность, полнота, тестируемость, консистентность.
4. Попросить не только замечания, но и исправленный вариант.
5. Проверить исправления вручную и зафиксировать финальную версию в артефакте проекта.

## Ограничения и риски

- LLM может уверенно предлагать неверные детали предметной области.
- Без контекста проекта модель дает "типовые", но бесполезные советы.
- Есть риск утечки чувствительных данных при работе с внешними сервисами.

Как снижать риски:

- Обезличивать данные.
- Давать модели структуру и факты, а не общий вопрос "сделай хорошо".
- Использовать LLM как рецензента, а не как единственный источник истины.

## Метрики качества

- Доля требований с измеримыми acceptance criteria.
- Количество найденных противоречий до старта разработки.
- Процент user story, прошедших ревью без возврата.
- Количество дефектов, связанных с неполными требованиями.
- Покрытие требований тест-кейсами (traceability coverage).

## Заключение

Для аналитика LLM полезны как инструмент управления качеством. Ценность появляется там, где модель помогает рано находить пробелы, противоречия и нетестируемые формулировки.

Если встроить LLM в процесс ревью требований, диаграмм и контрактов, то команда получает более надежный вход в разработку, меньше переделок и выше предсказуемость результата.
А может и нет. Зависит от того повезёт ли вам с ответом от LLM или она решит выдать бред
